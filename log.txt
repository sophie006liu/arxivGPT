8/2/24

Tried 128 and 64 units of hidden units both yield just a repeat of a bunch of characters


8/3/24

Cleaned up the data by removing even more extraneous characters
and checked the encoding funciton for correctness
TODO: look at text generation function and see if it worksre epochs did no

8/5/24
tried more epochs (200, loss was 0.88 as opposed to  1.3 from 100) did not get very far
TODO: have the lstm trained on not just predicting the next char but rather tokens
-add padding and try sos and eos tokens
